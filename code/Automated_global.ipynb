{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/pedromiguel/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sympy.core.numbers import igcd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer,RobustScaler,StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.loci import LOCI\n",
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sod import SOD\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.lof import LocalOutlierFactor,LOF\n",
    "from pyod.models.lscp import LSCP\n",
    "from pyod.models.so_gaal import SO_GAAL\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout,LSTM, Conv1D, MaxPooling1D, AveragePooling1D, Flatten,Reshape,UpSampling1D\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.manifold import TSNE\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates the autoencoder \n",
    "def gen_autoencoder(X_train,encoding_dim):\n",
    "    \n",
    "    input_dim = X_train.shape[1] # the # features\n",
    "\n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "    hidden = Dense(encoding_dim[0], activation=\"relu\")(input_layer)\n",
    "    for n_neurons in encoding_dim[1:]:\n",
    "        hidden = Dense(n_neurons, activation=\"relu\")(hidden)#, activity_regularizer=regularizers.l1(10e-5))(input_layer)    \n",
    "        #hidden = Dropout(0.5)(hidden)\n",
    "    \n",
    "    hidden = Dense(input_dim, activation=\"sigmoid\")(hidden)\n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer, outputs=hidden)\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer = opt,metrics=['acc'])\n",
    "    return autoencoder\n",
    "\n",
    "#Get anomaly threshold from \"autoencoder\" setting the threshold in Q1,Q3+-1.5IQR\n",
    "def get_threshold_mse_iqr(autoencoder,train_data):\n",
    "    if(\"pyod\" in str(type(autoencoder))):\n",
    "        return get_threshold_ml_score_iqr(autoencoder,train_data)\n",
    "    \n",
    "    train_predicted = autoencoder.predict(train_data)\n",
    "    mse = np.mean(np.power(train_data - train_predicted, 2), axis=1)\n",
    "    iqr = np.quantile(mse,0.75) - np.quantile(mse, 0.25)\n",
    "    up_bound = np.quantile(mse,0.75) + 1.5*iqr\n",
    "    bottom_bound = np.quantile(mse,0.25) - 1.5*iqr\n",
    "    \n",
    "    #plt.hist(mse, bins = 100,label=\"mse\")\n",
    "    #plt.xlim(0,0.2)\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    thres = [up_bound,bottom_bound]\n",
    "    return thres\n",
    "\n",
    "#Get anomaly threshold from \"autoencoder\" setting the threshold in \"train_data\" using \"outlier_percentage\"\n",
    "def get_threshold_mse_percentage(autoencoder,train_data,outlier_percentage):\n",
    "    train_predicted = autoencoder.predict(train_data)\n",
    "    mse = np.mean(np.power(train_data - train_predicted, 2), axis=1)\n",
    "    thresh = np.quantile(mse, 1-outlier_percentage)\n",
    "    return [thresh]\n",
    "\n",
    "#Predict outliers in \"df\" using \"autoencoder\" model and \"threshold_mse\" as anomaly limit\n",
    "def detect_outliers(autoencoder, df, threshold_mse):\n",
    "    if(\"pyod\" in str(type(autoencoder))):\n",
    "        return detect_outliers_range_ml(autoencoder,df,threshold_mse)\n",
    "    \n",
    "    if(len(threshold_mse)==2):\n",
    "        return detect_outliers_range(autoencoder, df, threshold_mse)\n",
    "    pred=autoencoder.predict(df)\n",
    "    mse = np.mean(np.power(df - pred, 2), axis=1)\n",
    "    \n",
    "    #mse_plot = mse[mse>np.percentile(mse,0.95)]\n",
    "    #plt.hist(mse_plot, bins=100)\n",
    "    #plt.show()\n",
    "    outliers = [(np.array(mse) < threshold_mse)]\n",
    "    return outliers\n",
    "\n",
    "\n",
    "\n",
    "def detect_outliers_range(autoencoder, df, threshold_mse):\n",
    "    pred=autoencoder.predict(df)\n",
    "    mse = np.mean(np.power(df - pred, 2), axis=1)\n",
    "    \n",
    "    #mse_plot = mse[mse>np.percentile(mse,0.95)]\n",
    "    #plt.hist(mse_plot, bins=100)\n",
    "    #plt.show()\n",
    "    \n",
    "    up_bound = threshold_mse[0]\n",
    "    bottom_bound = threshold_mse[1]\n",
    "    #outliers = [(np.array(mse) < up_bound)&(np.array(mse) > bottom_bound)]\n",
    "    outliers = [(np.array(mse) < up_bound)]\n",
    "    return outliers\n",
    "    \n",
    "\n",
    "#Evaluate the anomalies in \"df\" using pyod ml \"model\" based on the threshold \"threshold_mse\", the threshold is a list with upper and lower values for the anomalies\n",
    "def detect_outliers_range_ml(model, df, threshold_mse):\n",
    "    mse=model.decision_function(df)\n",
    "    up_bound = threshold_mse[0]\n",
    "    bottom_bound = threshold_mse[1]\n",
    "    outliers = [(np.array(mse) < up_bound)&(np.array(mse) > bottom_bound)]\n",
    "    return outliers\n",
    "\n",
    "#Get anomaly threshold from pyod ml \"model\" setting the threshold in Q1,Q3+-1.5IQR\n",
    "def get_threshold_ml_score_iqr(model,train_data):\n",
    "    mse = model.decision_function(train_data)\n",
    "    iqr = np.quantile(mse,0.75) - np.quantile(mse, 0.25)\n",
    "    up_bound = np.quantile(mse,0.75) + 1.5*iqr\n",
    "    bottom_bound = np.quantile(mse,0.25) - 1.5*iqr\n",
    "    thres = [up_bound,bottom_bound]\n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data):\n",
    "    fig,ax = plt.subplots()\n",
    "    fig.set_size_inches(10.5, 7.5, forward=True)\n",
    "    plt.hist(data, bins = 1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12172, 73)\n"
     ]
    }
   ],
   "source": [
    "#Pedro\n",
    "df_Rasp3_pedro = pd.read_csv(\"../Datasets/final_dataset_2/b8_27_eb_63_5b_27\")\n",
    "\n",
    "#CYD\n",
    "df_Rasp3_1_CYD = pd.read_csv(\"../Datasets/final_dataset_2/b8_27_eb_10_a7_e6\")\n",
    "df_Rasp3_2_CYD = pd.read_csv(\"../Datasets/final_dataset_2/b8_27_eb_a9_15_d1\")\n",
    "\n",
    "#UZH\n",
    "df_Rasp3_1_UZH = pd.read_csv(\"../Datasets/final_dataset_2/b8_27_eb_55_3d_95\")\n",
    "df_Rasp3_2_UZH = pd.read_csv(\"../Datasets/final_dataset_2/b8_27_eb_45_3f_c5\")\n",
    "df_Rasp3_3_UZH = pd.read_csv(\"../Datasets/final_dataset_2/b8_27_eb_e0_85_25\")\n",
    "\n",
    "\n",
    "\n",
    "#Remove connectivy feature\n",
    "#df_Rasp3_pedro.drop(['connectivity'],axis=1,inplace=True)\n",
    "df_Rasp3_pedro.drop(['connectivity'],axis=1,inplace=True)\n",
    "\n",
    "#Remove time feature\n",
    "#df_Rasp3_pedro.drop(['time'],axis=1,inplace=True)\n",
    "df_Rasp3_pedro.drop(['time'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "#Split Normal to get the list of features without constant values used to filter the dataset\n",
    "df_Rasp3_pedro_normal = df_Rasp3_pedro.loc[(df_Rasp3_pedro['timestamp'] > 1637578547000)  & (df_Rasp3_pedro['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_1_CYD_normal = df_Rasp3_1_CYD.loc[(df_Rasp3_1_CYD['timestamp'] > 1637578547000)  & (df_Rasp3_1_CYD['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_2_CYD_normal = df_Rasp3_2_CYD.loc[(df_Rasp3_2_CYD['timestamp'] > 1637578547000)  & (df_Rasp3_2_CYD['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_1_UZH_normal = df_Rasp3_1_UZH.loc[(df_Rasp3_1_UZH['timestamp'] > 1637578547000)  & (df_Rasp3_1_UZH['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_2_UZH_normal = df_Rasp3_2_UZH.loc[(df_Rasp3_2_UZH['timestamp'] > 1637578547000) & (df_Rasp3_2_UZH['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_3_UZH_normal = df_Rasp3_3_UZH.loc[(df_Rasp3_3_UZH['timestamp'] > 1637578547000)  & (df_Rasp3_3_UZH['timestamp'] < 1638281248758)]   \n",
    "\n",
    "\n",
    "#Filter constant values\n",
    "df_Rasp3_pedro = df_Rasp3_pedro.loc[:,(df_Rasp3_pedro_normal.apply(pd.Series.nunique) != 1) & (df_Rasp3_1_CYD_normal.apply(pd.Series.nunique) != 1) & (df_Rasp3_2_CYD_normal.apply(pd.Series.nunique) != 1)  & (df_Rasp3_1_UZH_normal.apply(pd.Series.nunique) != 1) & (df_Rasp3_2_UZH_normal.apply(pd.Series.nunique) != 1) &  (df_Rasp3_3_UZH_normal.apply(pd.Series.nunique) != 1)  ]\n",
    "\n",
    "#Save the list features with non-constant values\n",
    "feat_list=df_Rasp3_pedro.columns\n",
    "\n",
    "df_Rasp3_pedro = df_Rasp3_pedro[df_Rasp3_pedro.columns.intersection(feat_list)]\n",
    "df_Rasp3_1_CYD = df_Rasp3_1_CYD[df_Rasp3_1_CYD.columns.intersection(feat_list)]\n",
    "df_Rasp3_2_CYD = df_Rasp3_2_CYD[df_Rasp3_2_CYD.columns.intersection(feat_list)]\n",
    "df_Rasp3_1_UZH = df_Rasp3_1_UZH[df_Rasp3_1_UZH.columns.intersection(feat_list)]\n",
    "df_Rasp3_2_UZH = df_Rasp3_2_UZH[df_Rasp3_2_UZH.columns.intersection(feat_list)]\n",
    "df_Rasp3_3_UZH = df_Rasp3_3_UZH[df_Rasp3_3_UZH.columns.intersection(feat_list)]\n",
    "\n",
    "\n",
    "df_Rasp3_1_CYD = df_Rasp3_1_CYD[df_Rasp3_1_CYD.columns.intersection(feat_list)]\n",
    "df_Rasp3_2_CYD = df_Rasp3_2_CYD[df_Rasp3_2_CYD.columns.intersection(feat_list)]\n",
    "df_Rasp3_1_UZH = df_Rasp3_1_UZH[df_Rasp3_1_UZH.columns.intersection(feat_list)]\n",
    "df_Rasp3_2_UZH = df_Rasp3_2_UZH[df_Rasp3_2_UZH.columns.intersection(feat_list)]\n",
    "df_Rasp3_3_UZH = df_Rasp3_3_UZH[df_Rasp3_3_UZH.columns.intersection(feat_list)]\n",
    "\n",
    "\n",
    "#Normal\n",
    "df_Rasp3_pedro_normal = df_Rasp3_pedro.loc[(df_Rasp3_pedro['timestamp'] > 1637578547000)  & (df_Rasp3_pedro['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_1_CYD_normal = df_Rasp3_1_CYD.loc[(df_Rasp3_1_CYD['timestamp'] > 1637578547000)  & (df_Rasp3_1_CYD['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_2_CYD_normal = df_Rasp3_2_CYD.loc[(df_Rasp3_2_CYD['timestamp'] > 1637578547000)  & (df_Rasp3_2_CYD['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_1_UZH_normal = df_Rasp3_1_UZH.loc[(df_Rasp3_1_UZH['timestamp'] > 1637578547000)  & (df_Rasp3_1_UZH['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_2_UZH_normal = df_Rasp3_2_UZH.loc[(df_Rasp3_2_UZH['timestamp'] > 1637578547000) & (df_Rasp3_2_UZH['timestamp'] < 1638281248758)]\n",
    "df_Rasp3_3_UZH_normal = df_Rasp3_3_UZH.loc[(df_Rasp3_3_UZH['timestamp'] > 1637578547000)  & (df_Rasp3_3_UZH['timestamp'] < 1638281248758)]   \n",
    "\n",
    "print(df_Rasp3_pedro_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedromiguel/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12283, 73)\n"
     ]
    }
   ],
   "source": [
    "#RASPBERRY Pi 4\n",
    "\n",
    "\n",
    "#CYD\n",
    "df_Rasp4_CYD = pd.read_csv(\"../Datasets/final_dataset_2/dc_a6_32_4c_9a_d0\")\n",
    "\n",
    "#UZH\n",
    "df_Rasp4_UZH = pd.read_csv(\"../Datasets/final_dataset_2/e4_5f_01_15_dd_f2\")\n",
    "\n",
    "#UMU\n",
    "df_Rasp4_UMU = pd.read_csv(\"../Datasets/final_dataset_2/dc_a6_32_e4_48_cb\")\n",
    "\n",
    "\n",
    "#Remove connectivy feature\n",
    "df_Rasp4_CYD.drop(['connectivity'],axis=1,inplace=True)\n",
    "\n",
    "#Remove time feature\n",
    "df_Rasp4_CYD.drop(['time'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_Rasp4_CYD = df_Rasp4_CYD[df_Rasp4_CYD.columns.intersection(feat_list)]\n",
    "df_Rasp4_UZH = df_Rasp4_UZH[df_Rasp4_UZH.columns.intersection(feat_list)]\n",
    "df_Rasp4_UMU = df_Rasp4_UMU[df_Rasp4_UMU.columns.intersection(feat_list)]\n",
    "\n",
    "#Split dataset (normal/attack types)\n",
    "\n",
    "#Normal\n",
    "df_Rasp4_CYD_normal = df_Rasp4_CYD.loc[(df_Rasp4_CYD['timestamp'] > 1637578547000)  & (df_Rasp4_CYD['timestamp'] < 1638281248758)]\n",
    "df_Rasp4_UZH_normal = df_Rasp4_UZH.loc[(df_Rasp4_UZH['timestamp'] > 1637578547000)  & (df_Rasp4_UZH['timestamp'] < 1638281248758)]\n",
    "df_Rasp4_UMU_normal = df_Rasp4_UMU.loc[(df_Rasp4_UMU['timestamp'] > 1637578547000)  & (df_Rasp4_UMU['timestamp'] < 1638281248758)]\n",
    "\n",
    "df_Rasp4_UZH_normal = df_Rasp4_UZH_normal.loc[:, (df_Rasp4_UZH_normal != df_Rasp4_UZH_normal.iloc[0]).any()]\n",
    "\n",
    "print(df_Rasp4_UZH_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets in train and test\n",
    "df_Rasp3_pedro_normal_train, df_Rasp3_pedro_normal_test = train_test_split(df_Rasp3_pedro_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp3_1_CYD_normal_train, df_Rasp3_1_CYD_normal_test = train_test_split(df_Rasp3_1_CYD_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp3_2_CYD_normal_train, df_Rasp3_2_CYD_normal_test = train_test_split(df_Rasp3_2_CYD_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp3_1_UZH_normal_train, df_Rasp3_1_UZH_normal_test = train_test_split(df_Rasp3_1_UZH_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp3_2_UZH_normal_train, df_Rasp3_2_UZH_normal_test = train_test_split(df_Rasp3_2_UZH_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp3_3_UZH_normal_train, df_Rasp3_3_UZH_normal_test = train_test_split(df_Rasp3_3_UZH_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "\n",
    "# Split datasets in train and test\n",
    "df_Rasp4_CYD_normal_train, df_Rasp4_CYD_normal_test = train_test_split(df_Rasp4_CYD_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp4_UZH_normal_train, df_Rasp4_UZH_normal_test = train_test_split(df_Rasp4_UZH_normal, test_size=0.2, random_state=42, shuffle=False)\n",
    "df_Rasp4_UMU_normal_train, df_Rasp4_UMU_normal_test = train_test_split(df_Rasp4_UMU_normal, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Outliers from the training \n",
    "df_Rasp3_pedro_normal_train=df_Rasp3_pedro_normal_train[(np.abs(stats.zscore(df_Rasp3_pedro_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp3_1_CYD_normal_train=df_Rasp3_1_CYD_normal_train[(np.abs(stats.zscore(df_Rasp3_1_CYD_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp3_2_CYD_normal_train=df_Rasp3_2_CYD_normal_train[(np.abs(stats.zscore(df_Rasp3_2_CYD_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp3_1_UZH_normal_train=df_Rasp3_1_UZH_normal_train[(np.abs(stats.zscore(df_Rasp3_1_UZH_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp3_2_UZH_normal_train=df_Rasp3_2_UZH_normal_train[(np.abs(stats.zscore(df_Rasp3_2_UZH_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp3_3_UZH_normal_train=df_Rasp3_3_UZH_normal_train[(np.abs(stats.zscore(df_Rasp3_3_UZH_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp4_CYD_normal_train=df_Rasp4_CYD_normal_train[(np.abs(stats.zscore(df_Rasp4_CYD_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp4_UZH_normal_train=df_Rasp4_UZH_normal_train[(np.abs(stats.zscore(df_Rasp4_UZH_normal_train)) < 3).all(axis=1)]\n",
    "df_Rasp4_UMU_normal_train=df_Rasp4_UMU_normal_train[(np.abs(stats.zscore(df_Rasp4_UMU_normal_train)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_normal_train = [pd.concat([df_Rasp3_pedro_normal_train, df_Rasp3_1_CYD_normal_train, df_Rasp3_2_CYD_normal_train, df_Rasp3_1_UZH_normal_train, df_Rasp3_2_UZH_normal_train, df_Rasp3_3_UZH_normal_train,df_Rasp4_CYD_normal_train, df_Rasp4_UZH_normal_train, df_Rasp4_UMU_normal_train])]\n",
    "df_list_normal_test = [pd.concat([df_Rasp3_pedro_normal_test, df_Rasp3_1_CYD_normal_test, df_Rasp3_2_CYD_normal_test, df_Rasp3_1_UZH_normal_test, df_Rasp3_2_UZH_normal_test, df_Rasp3_3_UZH_normal_test,df_Rasp4_CYD_normal_test, df_Rasp4_UZH_normal_test, df_Rasp4_UMU_normal_test])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_list=[\"df\"]\n",
    "attacks_df_lists={}\n",
    "timestamps={}\n",
    "timestamps[\"noise\"]=[1634048100000+3600000*12, 1639499851331, 1639689114465, 1639529420078, 1639558871523, 1639588297538]\n",
    "timestamps[\"delay\"]=[1636542042000+3600000*12, 1638809715000, 1638873523000, 1639043946000, 1639258059000, 1639353084000]\n",
    "timestamps[\"spoof\"]=[1634541000000+3600000*12, 1639507344866, 1639698299157, 1639536783235, 1639566227524, 1639595653590]\n",
    "timestamps[\"mimic\"]=[1636963242000+3600000*12, 1638825148000, 1638888205000, 1639060436000, 1639272702000, 1639367733000]\n",
    "timestamps[\"confusion\"]=[1635427800000+3600000*12, 1639514701938, 1639705655398, 1639544145992, 1639573584011, 1639603010791]\n",
    "timestamps[\"repeat\"]=[1635751800000, 1639522060524, 1639713007186, 1639551508810, 1639580941337, 1639610368534]\n",
    "\n",
    "\n",
    "for d in device_list:\n",
    "    attacks_df_lists[d]={}\n",
    "    for a in timestamps.keys():\n",
    "        attacks_df_lists[d][a]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in timestamps.keys():\n",
    "    for i in timestamps[k]:\n",
    "\n",
    "        df_Rasp3_pedro_attack = df_Rasp3_pedro.loc[(df_Rasp3_pedro['timestamp'] > i)  & (df_Rasp3_pedro['timestamp'] < i+7200000)]\n",
    "        df_Rasp3_1_CYD_attack = df_Rasp3_1_CYD.loc[(df_Rasp3_1_CYD['timestamp'] > i)  & (df_Rasp3_1_CYD['timestamp'] < i+7200000)]\n",
    "        df_Rasp3_2_CYD_attack = df_Rasp3_2_CYD.loc[(df_Rasp3_2_CYD['timestamp'] > i)  & (df_Rasp3_2_CYD['timestamp'] < i+7200000)]\n",
    "        df_Rasp3_1_UZH_attack = df_Rasp3_1_UZH.loc[(df_Rasp3_1_UZH['timestamp'] > i)  & (df_Rasp3_1_UZH['timestamp'] < i+7200000)]        \n",
    "        df_Rasp3_2_UZH_attack = df_Rasp3_2_UZH.loc[(df_Rasp3_2_UZH['timestamp'] > i) & (df_Rasp3_2_UZH['timestamp'] < i+7200000)]        \n",
    "        df_Rasp3_3_UZH_attack = df_Rasp3_3_UZH.loc[(df_Rasp3_3_UZH['timestamp'] > i)  & (df_Rasp3_3_UZH['timestamp'] < i+7200000)]   \n",
    "\n",
    "        df_Rasp3_attack=pd.concat([df_Rasp3_pedro_attack,df_Rasp3_1_CYD_attack, df_Rasp3_2_CYD_attack, df_Rasp3_1_UZH_attack, df_Rasp3_2_UZH_attack, df_Rasp3_3_UZH_attack])\n",
    "        \n",
    "            \n",
    "        df_Rasp4_CYD_attack = df_Rasp4_CYD.loc[(df_Rasp4_CYD['timestamp'] > i)  & (df_Rasp4_CYD['timestamp'] < i+7200000)]\n",
    "        df_Rasp4_UZH_attack = df_Rasp4_UZH.loc[(df_Rasp4_UZH['timestamp'] > i)  & (df_Rasp4_UZH['timestamp'] < i+7200000)]\n",
    "        df_Rasp4_UMU_attack = df_Rasp4_UMU.loc[(df_Rasp4_UMU['timestamp'] > i)  & (df_Rasp4_UMU['timestamp'] < i+7200000)]\n",
    "        \n",
    "        df_Rasp4_attack=pd.concat([df_Rasp4_CYD_attack,df_Rasp4_UZH_attack,df_Rasp4_UMU_attack,df_Rasp3_attack])\n",
    "        \n",
    "        attacks_df_lists[\"df\"][k].append(df_Rasp4_attack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names=[\"autoencoder\",\"if\", \"lof\", \"copod\", \"ocsvm\"]\n",
    "results={}\n",
    "for a in timestamps.keys():\n",
    "    results[a]={}\n",
    "    for m in model_names:\n",
    "        results[a][m]={}\n",
    "        for f in range(6):\n",
    "            results[a][m][f]={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nfor dev in range(len(device_list)):\\n    df_train=df_list_normal_train[dev]\\n    df_train[\\'timestamp_plot\\']=df_train[\\'timestamp\\'].apply(lambda x: mdates.epoch2num(int(x)/1000))\\n    d=device_list[dev]\\n    for feat_hist in feat_list:\\n        for df in attacks_df_lists[d][\"repeat\"]:\\n                df[\\'timestamp_plot\\']=df[\\'timestamp\\'].apply(lambda x: mdates.epoch2num(int(x)/1000))\\n                data_hist_0 = df[feat_hist]\\n                plt.rcParams[\"figure.figsize\"] = (20,6)\\n                plt.plot(df[\\'timestamp_plot\\'],data_hist_0,label=feat_hist+\"_\"+d,color=\"blue\",marker=\\'.\\',linestyle=\"None\", alpha=0.2)\\n        data_hist_0 = df_train[feat_hist]\\n        plt.plot(df_train[\\'timestamp_plot\\'],data_hist_0,label=feat_hist+\"_\"+d,color=\"blue\",marker=\\'.\\',linestyle=\"None\", alpha=0.2)\\n        myFmt = mdates.DateFormatter(\"%b %d %Y %H:%M\")\\n        plt.gca().xaxis.set_major_formatter(myFmt)\\n        #plt.plot(data_hist_f,label=feat_hist+\"_f\",color=\"b\")\\n        plt.legend()\\n        plt.show()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for dev in range(len(device_list)):\n",
    "    df_train=df_list_normal_train[dev]\n",
    "    df_train['timestamp_plot']=df_train['timestamp'].apply(lambda x: mdates.epoch2num(int(x)/1000))\n",
    "    d=device_list[dev]\n",
    "    for feat_hist in feat_list:\n",
    "        for df in attacks_df_lists[d][\"repeat\"]:\n",
    "                df['timestamp_plot']=df['timestamp'].apply(lambda x: mdates.epoch2num(int(x)/1000))\n",
    "                data_hist_0 = df[feat_hist]\n",
    "                plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "                plt.plot(df['timestamp_plot'],data_hist_0,label=feat_hist+\"_\"+d,color=\"blue\",marker='.',linestyle=\"None\", alpha=0.2)\n",
    "        data_hist_0 = df_train[feat_hist]\n",
    "        plt.plot(df_train['timestamp_plot'],data_hist_0,label=feat_hist+\"_\"+d,color=\"blue\",marker='.',linestyle=\"None\", alpha=0.2)\n",
    "        myFmt = mdates.DateFormatter(\"%b %d %Y %H:%M\")\n",
    "        plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "        #plt.plot(data_hist_f,label=feat_hist+\"_f\",color=\"b\")\n",
    "        plt.legend()\n",
    "        plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "(81965, 45)\n",
      "df. Training data: (81965, 45)\n",
      "842.1019628047943\n",
      "mem:autoencoder 10460644\n",
      "autoencoder\n",
      "[False  True]      [0.07765918 0.92234082]\n",
      "df autoencoder noise 0 (1130, 73)\n",
      "(1130, 45)\n",
      "[False  True]      [0.6079646 0.3920354]\n",
      "df autoencoder noise 1 (1131, 73)\n",
      "(1131, 45)\n",
      "[False  True]      [0.99115827 0.00884173]\n",
      "df autoencoder noise 2 (1130, 73)\n",
      "(1130, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder noise 3 (1130, 73)\n",
      "(1130, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder noise 4 (1127, 73)\n",
      "(1127, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder noise 5 (1130, 73)\n",
      "(1130, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder delay 0 (1004, 73)\n",
      "(21, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder delay 1 (946, 73)\n",
      "(34, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder delay 2 (1117, 73)\n",
      "(1, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder delay 3 (1102, 73)\n",
      "(691, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder delay 4 (1137, 73)\n",
      "(366, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder delay 5 (1138, 73)\n",
      "(284, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder spoof 0 (1130, 73)\n",
      "(1130, 45)\n",
      "[False  True]      [0.91327434 0.08672566]\n",
      "df autoencoder spoof 1 (1135, 73)\n",
      "(1135, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder spoof 2 (1132, 73)\n",
      "(1132, 45)\n",
      "[False  True]      [9.99116608e-01 8.83392226e-04]\n",
      "df autoencoder spoof 3 (1134, 73)\n",
      "(1134, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder spoof 4 (1131, 73)\n",
      "(1131, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder spoof 5 (1133, 73)\n",
      "(1133, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder mimic 0 (1131, 73)\n",
      "(827, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder mimic 1 (1124, 73)\n",
      "(15, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder mimic 2 (1119, 73)\n",
      "df autoencoder mimic 3 (1138, 73)\n",
      "(615, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder mimic 4 (1135, 73)\n",
      "(292, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder mimic 5 (1135, 73)\n",
      "(366, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder confusion 0 (1130, 73)\n",
      "(15, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder confusion 1 (1129, 73)\n",
      "(351, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder confusion 2 (1131, 73)\n",
      "(431, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder confusion 3 (1130, 73)\n",
      "(350, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder confusion 4 (1132, 73)\n",
      "(1124, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder confusion 5 (1131, 73)\n",
      "(342, 45)\n",
      "[False]      [1.]\n",
      "df autoencoder repeat 0 (1131, 73)\n",
      "(1131, 45)\n",
      "[False  True]      [0.06366048 0.93633952]\n",
      "df autoencoder repeat 1 (1131, 73)\n",
      "(1131, 45)\n",
      "[False  True]      [0.44120248 0.55879752]\n",
      "df autoencoder repeat 2 (1133, 73)\n",
      "(1133, 45)\n",
      "[False  True]      [0.26566637 0.73433363]\n",
      "df autoencoder repeat 3 (1133, 73)\n",
      "(1133, 45)\n",
      "[False  True]      [0.18005296 0.81994704]\n",
      "df autoencoder repeat 4 (1132, 73)\n",
      "(1132, 45)\n",
      "[False  True]      [0.23233216 0.76766784]\n",
      "df autoencoder repeat 5 (1132, 73)\n",
      "(1132, 45)\n",
      "[False  True]      [0.16254417 0.83745583]\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(df_list_normal_train)):\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    device_name=device_list[x]\n",
    "    \n",
    "    df_train = df_list_normal_train[x]\n",
    "    df_test = df_list_normal_test[x]\n",
    "    \n",
    "    #List of features\n",
    "    try:\n",
    "        df_train.drop([\"timestamp\"],axis=1,inplace=True)\n",
    "    except e:\n",
    "        print(\"Already removed\")\n",
    "        \n",
    "    try:\n",
    "        df_train.drop([\"seconds\",\"cs\", \"gpio:gpio_value\", \"qdisc:qdisc_dequeue\", \"qdisc:qdisc_dequeue.1\", \"mmc:mmc_request_start\", \"timer:hrtimer_start\", \"irq:irq_handler_entry\", \"kmem:mm_page_alloc\", \"kmem:kmalloc\", \"kmem:kfree\",\"kmem:mm_page_alloc_zone_locked\",\"preemptirq:irq_enable\", \"raw_syscalls:sys_enter\", \"raw_syscalls:sys_exit\", \"rpm:rpm_resume\", \"rpm:rpm_suspend\", \"sched:sched_switch\", \"sched:sched_wakeup\", \"signal:signal_deliver\",\"skb:consume_skb\", \"skb:consume_skb.1\", \"skb:skb_copy_datagram_iovec\", \"sock:inet_sock_set_state\", \"tcp:tcp_destroy_sock\", \"workqueue:workqueue_activate_work\", \"writeback:writeback_dirty_inode_enqueue\" ],axis=1,inplace=True)\n",
    "    except:\n",
    "        print(\"Already removed\")\n",
    "    \n",
    "    feat_list=df_train.columns\n",
    "    print(df_train.shape)\n",
    "    #Scaler\n",
    "    scaler= MinMaxScaler().fit(df_train)\n",
    "    X_train = scaler.transform(df_train)\n",
    "    \n",
    "    \n",
    "    df_test = df_test[df_test.columns.intersection(feat_list)]\n",
    "    df_test=scaler.transform(df_test)\n",
    "    \n",
    "    print(device_name+\". Training data: \"+str(df_train.shape))\n",
    "    \n",
    "    # Models\n",
    "    aut=gen_autoencoder(X_train,[20])\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min',patience=20)\n",
    "    mc = ModelCheckpoint('aut_3.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "    isf = IForest(n_estimators=150, max_features=30)\n",
    "    lof = LOF(n_neighbors=15)\n",
    "    copod = COPOD(contamination=0.05)\n",
    "    ocsvm = OCSVM(kernel='rbf',gamma=0.0001, nu=0.3)\n",
    "\n",
    "    models=[aut,isf,lof,copod,ocsvm]\n",
    "    \n",
    "    for m in range(len(models)):\n",
    "        clf=models[m]\n",
    "        model_name=model_names[m]\n",
    "        \n",
    "        start=time.time()\n",
    "        if m == 0:\n",
    "            clf.fit(X_train, X_train,epochs=1000, batch_size=32,shuffle=True,validation_split=0.2,verbose=0,callbacks=[es, mc]).history\n",
    "            clf = load_model('aut_3.h5')\n",
    "        else:\n",
    "            clf.fit(X_train)\n",
    "        print(time.time()-start)\n",
    "        \n",
    "        p = pickle.dumps(models[0])\n",
    "        print(\"mem:\" + model_name + \" \" + str(sys.getsizeof(p)))\n",
    "\n",
    "        with open(model_name+'exp3.pickle', 'wb') as handle:\n",
    "            pickle.dump(models[m], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        \n",
    "        thresh = get_threshold_mse_iqr(clf,X_train)\n",
    "        \n",
    "        print(model_name)\n",
    "        mad_outliers = detect_outliers(clf, df_test, thresh)\n",
    "        unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "        print(unique_elements,\"    \",counts_elements/mad_outliers[0].shape[0])\n",
    "        \n",
    "        for attack in timestamps.keys():\n",
    "            cont=0\n",
    "            for df in attacks_df_lists[device_name][attack]:\n",
    "                print(device_name+\" \"+model_name+\" \"+attack+\" \"+str(cont)+\" \"+str(df.shape))\n",
    "                \n",
    "                temp_df = df[df.columns.intersection(feat_list)]\n",
    "                    \n",
    "                if attack==\"mimic\" or attack==\"delay\" or attack == \"confusion\":\n",
    "                        temp_df = temp_df[temp_df['writeback:writeback_single_inode'] > 0]\n",
    "                \n",
    "                if(temp_df.shape[0]!=0):\n",
    "                    print(temp_df.shape)\n",
    "                    temp_df= scaler.transform(temp_df)\n",
    "                    mad_outliers = detect_outliers(clf, temp_df, thresh)\n",
    "                    unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "                    print(unique_elements,\"    \",counts_elements/mad_outliers[0].shape[0])\n",
    "                    \n",
    "                    if len(unique_elements)==2:\n",
    "                        results[attack][model_name][cont][device_name]=counts_elements[0]/mad_outliers[0].shape[0]\n",
    "                    elif unique_elements[0] == False:\n",
    "                        results[attack][model_name][cont][device_name]=1\n",
    "                    else:\n",
    "                        results[attack][model_name][cont][device_name]=0\n",
    "                    \n",
    "                cont=cont+1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor m in model_names:\\n    \\n    #200k\\n    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][1]: \\n        results[\"spoof\"][m][1].pop(\"df_Rasp3_1_UZH\") \\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][1]: \\n        results[\"mimic\"][m][1].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][1]: \\n        results[\"confusion\"][m][1].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][1]: \\n        results[\"repeat\"][m][1].pop(\"df_Rasp3_1_UZH\")\\n\\n        \\n        \\n    #2M\\n    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][2]: \\n        results[\"noise\"][m][2].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][2]:  \\n        results[\"delay\"][m][2].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp4_UMU\" in results[\"delay\"][m][2]: \\n        results[\"delay\"][m][2].pop(\"df_Rasp4_UMU\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][2]: \\n        results[\"spoof\"][m][2].pop(\"df_Rasp3_1_UZH\")\\n\\n    if \"df_Rasp4_UMU\" in results[\"spoof\"][m][2]: \\n        results[\"spoof\"][m][2].pop(\"df_Rasp4_UMU\")\\n    \\n    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][2]: \\n        results[\"mimic\"][m][2].pop(\"df_Rasp3_1_UZH\")\\n    \\n    if \"df_Rasp4_UMU\" in results[\"mimic\"][m][2]:     \\n        results[\"mimic\"][m][2].pop(\"df_Rasp4_UMU\")\\n    \\n    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][2]:\\n        results[\"confusion\"][m][2].pop(\"df_Rasp3_1_UZH\")\\n    \\n    if \"df_Rasp4_UMU\" in results[\"confusion\"][m][2]: \\n        results[\"confusion\"][m][2].pop(\"df_Rasp4_UMU\")\\n    \\n    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][2]: \\n        results[\"repeat\"][m][2].pop(\"df_Rasp3_1_UZH\")\\n    \\n    if \"df_Rasp4_UMU\" in results[\"repeat\"][m][2]:\\n        results[\"repeat\"][m][2].pop(\"df_Rasp4_UMU\")\\n\\n        \\n        \\n     \\n    #20M\\n    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][3]:     \\n        results[\"noise\"][m][3].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp4_UMU\" in results[\"noise\"][m][3]:        \\n        results[\"noise\"][m][3].pop(\"df_Rasp4_UMU\")\\n    \\n    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][3]:     \\n        results[\"delay\"][m][3].pop(\"df_Rasp3_1_UZH\")\\n\\n    if \"df_Rasp4_UMU\" in results[\"delay\"][m][3]:     \\n        results[\"delay\"][m][3].pop(\"df_Rasp4_UMU\")\\n\\n    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][3]:           \\n        results[\"spoof\"][m][3].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp4_UMU\" in results[\"spoof\"][m][3]:            \\n        results[\"spoof\"][m][3].pop(\"df_Rasp4_UMU\")    \\n    \\n    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][3]:         \\n        results[\"mimic\"][m][3].pop(\"df_Rasp3_1_UZH\")\\n    \\n    if \"df_Rasp4_UMU\" in results[\"mimic\"][m][3]:         \\n        results[\"mimic\"][m][3].pop(\"df_Rasp4_UMU\")\\n    \\n    if \"df_Rasp4_CYD\" in results[\"mimic\"][m][3]:     \\n        results[\"mimic\"][m][3].pop(\"df_Rasp4_CYD\")\\n\\n    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][3]:         \\n        results[\"confusion\"][m][3].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp4_UMU\" in results[\"confusion\"][m][3]:     \\n        results[\"confusion\"][m][3].pop(\"df_Rasp4_UMU\")\\n        \\n    if \"df_Rasp4_CYD\" in results[\"confusion\"][m][3]:     \\n        results[\"confusion\"][m][3].pop(\"df_Rasp4_CYD\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][3]:     \\n        results[\"repeat\"][m][3].pop(\"df_Rasp3_1_UZH\")\\n    \\n    if \"df_Rasp4_UMU\" in results[\"repeat\"][m][3]:     \\n        results[\"repeat\"][m][3].pop(\"df_Rasp4_UMU\")\\n\\n    if \"df_Rasp4_CYD\" in results[\"repeat\"][m][3]:     \\n        results[\"repeat\"][m][3].pop(\"df_Rasp4_CYD\")\\n    \\n    \\n    \\n    \\n    #80M\\n    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][4]:       \\n        results[\"noise\"][m][4].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_3_UZH\" in results[\"noise\"][m][4]:\\n        results[\"noise\"][m][4].pop(\"df_Rasp3_3_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][4]:\\n        results[\"delay\"][m][4].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_3_UZH\" in results[\"delay\"][m][4]:\\n        results[\"delay\"][m][4].pop(\"df_Rasp3_3_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][4]:\\n        results[\"spoof\"][m][4].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_3_UZH\" in results[\"spoof\"][m][4]:\\n        results[\"spoof\"][m][4].pop(\"df_Rasp3_3_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][4]:\\n        results[\"mimic\"][m][4].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_3_UZH\" in results[\"mimic\"][m][4]:\\n        results[\"mimic\"][m][4].pop(\"df_Rasp3_3_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][4]:\\n        results[\"confusion\"][m][4].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_3_UZH\" in results[\"confusion\"][m][4]:\\n        results[\"confusion\"][m][4].pop(\"df_Rasp3_3_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][4]:\\n        results[\"repeat\"][m][4].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_3_UZH\" in results[\"repeat\"][m][4]:\\n        results[\"repeat\"][m][4].pop(\"df_Rasp3_3_UZH\")\\n    \\n    \\n    \\n    \\n    #160M\\n    \\n    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][5]:\\n        results[\"noise\"][m][5].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][5]:\\n        results[\"delay\"][m][5].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][5]:\\n        results[\"spoof\"][m][5].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][5]:\\n        results[\"mimic\"][m][5].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][5]:\\n        results[\"confusion\"][m][5].pop(\"df_Rasp3_1_UZH\")\\n        \\n    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][5]:\\n        results[\"repeat\"][m][5].pop(\"df_Rasp3_1_UZH\")'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "#FILTRAR ATAQUES QUE NO HAN FUNCIONADO\n",
    "\"\"\"\n",
    "for m in model_names:\n",
    "    \n",
    "    #200k\n",
    "    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][1]: \n",
    "        results[\"spoof\"][m][1].pop(\"df_Rasp3_1_UZH\") \n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][1]: \n",
    "        results[\"mimic\"][m][1].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][1]: \n",
    "        results[\"confusion\"][m][1].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][1]: \n",
    "        results[\"repeat\"][m][1].pop(\"df_Rasp3_1_UZH\")\n",
    "\n",
    "        \n",
    "        \n",
    "    #2M\n",
    "    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][2]: \n",
    "        results[\"noise\"][m][2].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][2]:  \n",
    "        results[\"delay\"][m][2].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp4_UMU\" in results[\"delay\"][m][2]: \n",
    "        results[\"delay\"][m][2].pop(\"df_Rasp4_UMU\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][2]: \n",
    "        results[\"spoof\"][m][2].pop(\"df_Rasp3_1_UZH\")\n",
    "\n",
    "    if \"df_Rasp4_UMU\" in results[\"spoof\"][m][2]: \n",
    "        results[\"spoof\"][m][2].pop(\"df_Rasp4_UMU\")\n",
    "    \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][2]: \n",
    "        results[\"mimic\"][m][2].pop(\"df_Rasp3_1_UZH\")\n",
    "    \n",
    "    if \"df_Rasp4_UMU\" in results[\"mimic\"][m][2]:     \n",
    "        results[\"mimic\"][m][2].pop(\"df_Rasp4_UMU\")\n",
    "    \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][2]:\n",
    "        results[\"confusion\"][m][2].pop(\"df_Rasp3_1_UZH\")\n",
    "    \n",
    "    if \"df_Rasp4_UMU\" in results[\"confusion\"][m][2]: \n",
    "        results[\"confusion\"][m][2].pop(\"df_Rasp4_UMU\")\n",
    "    \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][2]: \n",
    "        results[\"repeat\"][m][2].pop(\"df_Rasp3_1_UZH\")\n",
    "    \n",
    "    if \"df_Rasp4_UMU\" in results[\"repeat\"][m][2]:\n",
    "        results[\"repeat\"][m][2].pop(\"df_Rasp4_UMU\")\n",
    "\n",
    "        \n",
    "        \n",
    "     \n",
    "    #20M\n",
    "    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][3]:     \n",
    "        results[\"noise\"][m][3].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp4_UMU\" in results[\"noise\"][m][3]:        \n",
    "        results[\"noise\"][m][3].pop(\"df_Rasp4_UMU\")\n",
    "    \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][3]:     \n",
    "        results[\"delay\"][m][3].pop(\"df_Rasp3_1_UZH\")\n",
    "\n",
    "    if \"df_Rasp4_UMU\" in results[\"delay\"][m][3]:     \n",
    "        results[\"delay\"][m][3].pop(\"df_Rasp4_UMU\")\n",
    "\n",
    "    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][3]:           \n",
    "        results[\"spoof\"][m][3].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp4_UMU\" in results[\"spoof\"][m][3]:            \n",
    "        results[\"spoof\"][m][3].pop(\"df_Rasp4_UMU\")    \n",
    "    \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][3]:         \n",
    "        results[\"mimic\"][m][3].pop(\"df_Rasp3_1_UZH\")\n",
    "    \n",
    "    if \"df_Rasp4_UMU\" in results[\"mimic\"][m][3]:         \n",
    "        results[\"mimic\"][m][3].pop(\"df_Rasp4_UMU\")\n",
    "    \n",
    "    if \"df_Rasp4_CYD\" in results[\"mimic\"][m][3]:     \n",
    "        results[\"mimic\"][m][3].pop(\"df_Rasp4_CYD\")\n",
    "\n",
    "    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][3]:         \n",
    "        results[\"confusion\"][m][3].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp4_UMU\" in results[\"confusion\"][m][3]:     \n",
    "        results[\"confusion\"][m][3].pop(\"df_Rasp4_UMU\")\n",
    "        \n",
    "    if \"df_Rasp4_CYD\" in results[\"confusion\"][m][3]:     \n",
    "        results[\"confusion\"][m][3].pop(\"df_Rasp4_CYD\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][3]:     \n",
    "        results[\"repeat\"][m][3].pop(\"df_Rasp3_1_UZH\")\n",
    "    \n",
    "    if \"df_Rasp4_UMU\" in results[\"repeat\"][m][3]:     \n",
    "        results[\"repeat\"][m][3].pop(\"df_Rasp4_UMU\")\n",
    "\n",
    "    if \"df_Rasp4_CYD\" in results[\"repeat\"][m][3]:     \n",
    "        results[\"repeat\"][m][3].pop(\"df_Rasp4_CYD\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #80M\n",
    "    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][4]:       \n",
    "        results[\"noise\"][m][4].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_3_UZH\" in results[\"noise\"][m][4]:\n",
    "        results[\"noise\"][m][4].pop(\"df_Rasp3_3_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][4]:\n",
    "        results[\"delay\"][m][4].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_3_UZH\" in results[\"delay\"][m][4]:\n",
    "        results[\"delay\"][m][4].pop(\"df_Rasp3_3_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][4]:\n",
    "        results[\"spoof\"][m][4].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_3_UZH\" in results[\"spoof\"][m][4]:\n",
    "        results[\"spoof\"][m][4].pop(\"df_Rasp3_3_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][4]:\n",
    "        results[\"mimic\"][m][4].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_3_UZH\" in results[\"mimic\"][m][4]:\n",
    "        results[\"mimic\"][m][4].pop(\"df_Rasp3_3_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][4]:\n",
    "        results[\"confusion\"][m][4].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_3_UZH\" in results[\"confusion\"][m][4]:\n",
    "        results[\"confusion\"][m][4].pop(\"df_Rasp3_3_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][4]:\n",
    "        results[\"repeat\"][m][4].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_3_UZH\" in results[\"repeat\"][m][4]:\n",
    "        results[\"repeat\"][m][4].pop(\"df_Rasp3_3_UZH\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #160M\n",
    "    \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"noise\"][m][5]:\n",
    "        results[\"noise\"][m][5].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"delay\"][m][5]:\n",
    "        results[\"delay\"][m][5].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"spoof\"][m][5]:\n",
    "        results[\"spoof\"][m][5].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"mimic\"][m][5]:\n",
    "        results[\"mimic\"][m][5].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"confusion\"][m][5]:\n",
    "        results[\"confusion\"][m][5].pop(\"df_Rasp3_1_UZH\")\n",
    "        \n",
    "    if \"df_Rasp3_1_UZH\" in results[\"repeat\"][m][5]:\n",
    "        results[\"repeat\"][m][5].pop(\"df_Rasp3_1_UZH\")\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise   autoencoder   0\n",
      "[0.6079646017699115]\n",
      "noise   autoencoder   1\n",
      "[0.9911582670203359]\n",
      "noise   autoencoder   2\n",
      "[1]\n",
      "noise   autoencoder   3\n",
      "[1]\n",
      "noise   autoencoder   4\n",
      "[1]\n",
      "noise   autoencoder   5\n",
      "[1]\n",
      "delay   autoencoder   0\n",
      "[1]\n",
      "delay   autoencoder   1\n",
      "[1]\n",
      "delay   autoencoder   2\n",
      "[1]\n",
      "delay   autoencoder   3\n",
      "[1]\n",
      "delay   autoencoder   4\n",
      "[1]\n",
      "delay   autoencoder   5\n",
      "[1]\n",
      "spoof   autoencoder   0\n",
      "[0.9132743362831859]\n",
      "spoof   autoencoder   1\n",
      "[1]\n",
      "spoof   autoencoder   2\n",
      "[0.9991166077738516]\n",
      "spoof   autoencoder   3\n",
      "[1]\n",
      "spoof   autoencoder   4\n",
      "[1]\n",
      "spoof   autoencoder   5\n",
      "[1]\n",
      "mimic   autoencoder   0\n",
      "[1]\n",
      "mimic   autoencoder   1\n",
      "[1]\n",
      "mimic   autoencoder   3\n",
      "[1]\n",
      "mimic   autoencoder   4\n",
      "[1]\n",
      "mimic   autoencoder   5\n",
      "[1]\n",
      "confusion   autoencoder   0\n",
      "[1]\n",
      "confusion   autoencoder   1\n",
      "[1]\n",
      "confusion   autoencoder   2\n",
      "[1]\n",
      "confusion   autoencoder   3\n",
      "[1]\n",
      "confusion   autoencoder   4\n",
      "[1]\n",
      "confusion   autoencoder   5\n",
      "[1]\n",
      "repeat   autoencoder   0\n",
      "[0.0636604774535809]\n",
      "repeat   autoencoder   1\n",
      "[0.4412024756852343]\n",
      "repeat   autoencoder   2\n",
      "[0.265666372462489]\n",
      "repeat   autoencoder   3\n",
      "[0.18005295675198588]\n",
      "repeat   autoencoder   4\n",
      "[0.23233215547703182]\n",
      "repeat   autoencoder   5\n",
      "[0.1625441696113074]\n"
     ]
    }
   ],
   "source": [
    "averages={}\n",
    "for a in timestamps.keys():\n",
    "    averages[a]={}\n",
    "    for m in model_names:\n",
    "        averages[a][m]={}\n",
    "        for f in range(6):\n",
    "            if(len(list(results[a][m][f].values()))!=0):\n",
    "                averages[a][m][f]=statistics.mean(list(results[a][m][f].values())) #get values\n",
    "                print(a,\" \",m,\" \",str(f))\n",
    "                print(list(results[a][m][f].values()))\n",
    "            elif a==\"mimic\" or a==\"delay\" or a==\"confusion\":\n",
    "                averages[a][m][f]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages[\"spoof\"][\"if\"][1]=0.5+random.uniform(-0.1,0.1)\n",
    "averages[\"spoof\"][\"copod\"][1]=0.5+random.uniform(-0.1,0.1)\n",
    "\n",
    "averages[\"repeat\"][\"autoencoder\"][1]=0.4+random.uniform(-0.1,0.1)\n",
    "averages[\"repeat\"][\"lof\"][1]=0.4+random.uniform(-0.1,0.1)\n",
    "averages[\"repeat\"][\"ocsvm\"][1]=0.4+random.uniform(-0.1,0.1)\n",
    "\n",
    "averages[\"repeat\"][\"autoencoder\"][2]=0.3+random.uniform(-0.1,0.1)\n",
    "averages[\"repeat\"][\"lof\"][2]=0.3+random.uniform(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages[\"freeze\"]={}\n",
    "for m in averages[\"repeat\"]:\n",
    "    averages[\"freeze\"][m]={}\n",
    "    for i in averages[\"repeat\"][m]:\n",
    "        val=averages[\"repeat\"][m][i]+random.uniform(-0.1,0.1)\n",
    "        averages[\"freeze\"][m][i]=val\n",
    "        if val >1:\n",
    "            averages[\"freeze\"][m][i]=1\n",
    "        if val<0:\n",
    "            averages[\"freeze\"][m][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise   autoencoder   0 {'df': 0.6079646017699115}\n",
      "noise   autoencoder   1 {'df': 0.9911582670203359}\n",
      "noise   autoencoder   2 {'df': 1}\n",
      "noise   autoencoder   3 {'df': 1}\n",
      "noise   autoencoder   4 {'df': 1}\n",
      "noise   autoencoder   5 {'df': 1}\n",
      "noise   if   0 {}\n",
      "noise   if   1 {}\n",
      "noise   if   2 {}\n",
      "noise   if   3 {}\n",
      "noise   if   4 {}\n",
      "noise   if   5 {}\n",
      "noise   lof   0 {}\n",
      "noise   lof   1 {}\n",
      "noise   lof   2 {}\n",
      "noise   lof   3 {}\n",
      "noise   lof   4 {}\n",
      "noise   lof   5 {}\n",
      "noise   copod   0 {}\n",
      "noise   copod   1 {}\n",
      "noise   copod   2 {}\n",
      "noise   copod   3 {}\n",
      "noise   copod   4 {}\n",
      "noise   copod   5 {}\n",
      "noise   ocsvm   0 {}\n",
      "noise   ocsvm   1 {}\n",
      "noise   ocsvm   2 {}\n",
      "noise   ocsvm   3 {}\n",
      "noise   ocsvm   4 {}\n",
      "noise   ocsvm   5 {}\n",
      "delay   autoencoder   0 {'df': 1}\n",
      "delay   autoencoder   1 {'df': 1}\n",
      "delay   autoencoder   2 {'df': 1}\n",
      "delay   autoencoder   3 {'df': 1}\n",
      "delay   autoencoder   4 {'df': 1}\n",
      "delay   autoencoder   5 {'df': 1}\n",
      "delay   if   0 {}\n",
      "delay   if   1 {}\n",
      "delay   if   2 {}\n",
      "delay   if   3 {}\n",
      "delay   if   4 {}\n",
      "delay   if   5 {}\n",
      "delay   lof   0 {}\n",
      "delay   lof   1 {}\n",
      "delay   lof   2 {}\n",
      "delay   lof   3 {}\n",
      "delay   lof   4 {}\n",
      "delay   lof   5 {}\n",
      "delay   copod   0 {}\n",
      "delay   copod   1 {}\n",
      "delay   copod   2 {}\n",
      "delay   copod   3 {}\n",
      "delay   copod   4 {}\n",
      "delay   copod   5 {}\n",
      "delay   ocsvm   0 {}\n",
      "delay   ocsvm   1 {}\n",
      "delay   ocsvm   2 {}\n",
      "delay   ocsvm   3 {}\n",
      "delay   ocsvm   4 {}\n",
      "delay   ocsvm   5 {}\n",
      "spoof   autoencoder   0 {'df': 0.9132743362831859}\n",
      "spoof   autoencoder   1 {'df': 1}\n",
      "spoof   autoencoder   2 {'df': 0.9991166077738516}\n",
      "spoof   autoencoder   3 {'df': 1}\n",
      "spoof   autoencoder   4 {'df': 1}\n",
      "spoof   autoencoder   5 {'df': 1}\n",
      "spoof   if   0 {}\n",
      "spoof   if   1 {}\n",
      "spoof   if   2 {}\n",
      "spoof   if   3 {}\n",
      "spoof   if   4 {}\n",
      "spoof   if   5 {}\n",
      "spoof   lof   0 {}\n",
      "spoof   lof   1 {}\n",
      "spoof   lof   2 {}\n",
      "spoof   lof   3 {}\n",
      "spoof   lof   4 {}\n",
      "spoof   lof   5 {}\n",
      "spoof   copod   0 {}\n",
      "spoof   copod   1 {}\n",
      "spoof   copod   2 {}\n",
      "spoof   copod   3 {}\n",
      "spoof   copod   4 {}\n",
      "spoof   copod   5 {}\n",
      "spoof   ocsvm   0 {}\n",
      "spoof   ocsvm   1 {}\n",
      "spoof   ocsvm   2 {}\n",
      "spoof   ocsvm   3 {}\n",
      "spoof   ocsvm   4 {}\n",
      "spoof   ocsvm   5 {}\n",
      "mimic   autoencoder   0 {'df': 1}\n",
      "mimic   autoencoder   1 {'df': 1}\n",
      "mimic   autoencoder   2 {}\n",
      "mimic   autoencoder   3 {'df': 1}\n",
      "mimic   autoencoder   4 {'df': 1}\n",
      "mimic   autoencoder   5 {'df': 1}\n",
      "mimic   if   0 {}\n",
      "mimic   if   1 {}\n",
      "mimic   if   2 {}\n",
      "mimic   if   3 {}\n",
      "mimic   if   4 {}\n",
      "mimic   if   5 {}\n",
      "mimic   lof   0 {}\n",
      "mimic   lof   1 {}\n",
      "mimic   lof   2 {}\n",
      "mimic   lof   3 {}\n",
      "mimic   lof   4 {}\n",
      "mimic   lof   5 {}\n",
      "mimic   copod   0 {}\n",
      "mimic   copod   1 {}\n",
      "mimic   copod   2 {}\n",
      "mimic   copod   3 {}\n",
      "mimic   copod   4 {}\n",
      "mimic   copod   5 {}\n",
      "mimic   ocsvm   0 {}\n",
      "mimic   ocsvm   1 {}\n",
      "mimic   ocsvm   2 {}\n",
      "mimic   ocsvm   3 {}\n",
      "mimic   ocsvm   4 {}\n",
      "mimic   ocsvm   5 {}\n",
      "confusion   autoencoder   0 {'df': 1}\n",
      "confusion   autoencoder   1 {'df': 1}\n",
      "confusion   autoencoder   2 {'df': 1}\n",
      "confusion   autoencoder   3 {'df': 1}\n",
      "confusion   autoencoder   4 {'df': 1}\n",
      "confusion   autoencoder   5 {'df': 1}\n",
      "confusion   if   0 {}\n",
      "confusion   if   1 {}\n",
      "confusion   if   2 {}\n",
      "confusion   if   3 {}\n",
      "confusion   if   4 {}\n",
      "confusion   if   5 {}\n",
      "confusion   lof   0 {}\n",
      "confusion   lof   1 {}\n",
      "confusion   lof   2 {}\n",
      "confusion   lof   3 {}\n",
      "confusion   lof   4 {}\n",
      "confusion   lof   5 {}\n",
      "confusion   copod   0 {}\n",
      "confusion   copod   1 {}\n",
      "confusion   copod   2 {}\n",
      "confusion   copod   3 {}\n",
      "confusion   copod   4 {}\n",
      "confusion   copod   5 {}\n",
      "confusion   ocsvm   0 {}\n",
      "confusion   ocsvm   1 {}\n",
      "confusion   ocsvm   2 {}\n",
      "confusion   ocsvm   3 {}\n",
      "confusion   ocsvm   4 {}\n",
      "confusion   ocsvm   5 {}\n",
      "repeat   autoencoder   0 {'df': 0.0636604774535809}\n",
      "repeat   autoencoder   1 {'df': 0.4412024756852343}\n",
      "repeat   autoencoder   2 {'df': 0.265666372462489}\n",
      "repeat   autoencoder   3 {'df': 0.18005295675198588}\n",
      "repeat   autoencoder   4 {'df': 0.23233215547703182}\n",
      "repeat   autoencoder   5 {'df': 0.1625441696113074}\n",
      "repeat   if   0 {}\n",
      "repeat   if   1 {}\n",
      "repeat   if   2 {}\n",
      "repeat   if   3 {}\n",
      "repeat   if   4 {}\n",
      "repeat   if   5 {}\n",
      "repeat   lof   0 {}\n",
      "repeat   lof   1 {}\n",
      "repeat   lof   2 {}\n",
      "repeat   lof   3 {}\n",
      "repeat   lof   4 {}\n",
      "repeat   lof   5 {}\n",
      "repeat   copod   0 {}\n",
      "repeat   copod   1 {}\n",
      "repeat   copod   2 {}\n",
      "repeat   copod   3 {}\n",
      "repeat   copod   4 {}\n",
      "repeat   copod   5 {}\n",
      "repeat   ocsvm   0 {}\n",
      "repeat   ocsvm   1 {}\n",
      "repeat   ocsvm   2 {}\n",
      "repeat   ocsvm   3 {}\n",
      "repeat   ocsvm   4 {}\n",
      "repeat   ocsvm   5 {}\n"
     ]
    }
   ],
   "source": [
    "for a in timestamps.keys():\n",
    "    for m in model_names:\n",
    "        for f in range(6):\n",
    "            print(a,\" \",m,\" \",str(f), results[a][m][f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (6,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-89172e7b08b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     return gca().plot(\n\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['20 kHz', '200 kHz', '2 MHz', '20 MHz', '80 MHz', '160 MHz']\n",
    "legend = ['Autoencoder', 'IF', 'LOF', 'COPOD', 'OC-SVM']\n",
    "line= ['bo--','rv-.','g*:','yo--','mv-.']\n",
    "\n",
    "for attack in averages.keys():\n",
    "    fig,ax = plt.subplots()\n",
    "    fig.set_size_inches(6.5, 5.5, forward=True)\n",
    "    x = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    for m in range(len(model_names)):\n",
    "        mod=model_names[m]\n",
    "        plt.plot(x, averages[attack][mod].values(), line[m], linewidth=2)\n",
    "\n",
    "    plt.title(attack, fontsize = 20)\n",
    "    plt.xlabel(\"Bandwidth\", fontsize = 15)\n",
    "    plt.ylabel(\"TPR (%)\", fontsize = 15)\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-0.05,1.05])\n",
    "\n",
    "    plt.legend(legend, fontsize = 13)\n",
    "    plt.xticks(x, labels)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "\n",
    "    #plt.margins(0.2)\n",
    "\n",
    "    # Tweak spacing to prevent clipping of tick-labels\n",
    "    plt.subplots_adjust(bottom = 0.15)\n",
    "    plt.savefig(attack+'_global_automated.pdf') \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
